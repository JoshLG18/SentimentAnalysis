{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da792bd0",
   "metadata": {},
   "source": [
    "## LSTM - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ceb872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torchtext\n",
    "#%pip install torchdata\n",
    "#%pip install torchdata==0.7.1\n",
    "#%pip install portalocker\n",
    "#%pip install datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f8e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "import math\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "\n",
    "# set device\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# set seed\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)                           # Python random\n",
    "    np.random.seed(seed)                        # NumPy\n",
    "    torch.manual_seed(seed)                     # PyTorch CPU\n",
    "    torch.cuda.manual_seed_all(seed)            # PyTorch GPU (if using)\n",
    "    torch.backends.cudnn.deterministic = True   # For reproducibility\n",
    "    torch.backends.cudnn.benchmark = False      # Disable auto-tuning (slower but stable)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ========== Hyperparameters ==========\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 64\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "MAX_LEN = 300\n",
    "LEARNING_RATE = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149693fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Find some twitter data ============\n",
    "\n",
    "# train_data = dataset[\"train\"]\n",
    "# test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ce9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Tokenizer and GloVe ==========\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "glove = GloVe(name=\"6B\", dim=EMBEDDING_DIM)\n",
    "\n",
    "def yield_glove_tokens(data_iter):\n",
    "    for example in data_iter:\n",
    "        tokens = tokenizer(example[\"text\"])\n",
    "        yield [token for token in tokens if token in glove.stoi]\n",
    "\n",
    "# ========== Build Vocab (only GloVe tokens) ==========\n",
    "vocab = build_vocab_from_iterator(yield_glove_tokens(train_data), specials=[\"<pad>\", \"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# ========== GloVe Coverage Check ==========\n",
    "known = sum(1 for token in vocab.get_itos() if token in glove.stoi)\n",
    "print(f\"GloVe coverage: {known / len(vocab):.2%}\")\n",
    "\n",
    "# ========== Preprocessing ==========\n",
    "def preprocess(example):\n",
    "    tokens = tokenizer(example[\"text\"])\n",
    "    input_ids = vocab(tokens)[:MAX_LEN]\n",
    "    label = int(example[\"label\"])\n",
    "    return {\"input_ids\": input_ids, \"label\": label}\n",
    "\n",
    "train_data = train_data.map(preprocess)\n",
    "test_data = test_data.map(preprocess)\n",
    "train_data.set_format(type=\"python\", columns=[\"input_ids\", \"label\"])\n",
    "test_data.set_format(type=\"python\", columns=[\"input_ids\", \"label\"])\n",
    "\n",
    "# ========== Collate Function ==========\n",
    "def collate_batch(batch):\n",
    "    texts = [torch.tensor(sample[\"input_ids\"], dtype=torch.int64) for sample in batch]\n",
    "    labels = [torch.tensor(sample[\"label\"], dtype=torch.float32) for sample in batch]\n",
    "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "    return texts_padded.to(device), torch.stack(labels).to(device)\n",
    "\n",
    "# ========== DataLoaders ==========\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          collate_fn=collate_batch, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=collate_batch, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ========== Check Class Balance ==========\n",
    "print(\"Label distribution in training set:\")\n",
    "print(Counter([sample[\"label\"] for sample in train_data]))\n",
    "\n",
    "# ========== Build Embedding Matrix ==========\n",
    "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
    "\n",
    "for idx, token in enumerate(vocab.get_itos()):\n",
    "    if token in glove.stoi:\n",
    "        embedding_matrix[idx] = glove[token]\n",
    "    else:\n",
    "        embedding_matrix[idx] = torch.randn(EMBEDDING_DIM) * 0.6  # small random vector for unknowns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "940084da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMSentiment(\n",
       "  (embedding): Embedding(63925, 50, padding_idx=0)\n",
       "  (lstm): LSTM(50, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (attention): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crearte the LSTM model\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1):\n",
    "        super(LSTMSentiment, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=vocab[\"<pad>\"]) # embedding layer\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, \n",
    "                            batch_first=True, bidirectional=True, dropout=0.2) # LSTM layer\n",
    "        self.attention = nn.Linear(hidden_dim*2, hidden_dim*2) # Attention layer\n",
    "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) # run the embedding layer\n",
    "        lstm_out, _ = self.lstm(x) # run lstm layer\n",
    "\n",
    "        att_scores = self.attention(lstm_out) # compute attention scores\n",
    "        attn_weights = torch.softmax(att_scores, dim=1) # normalize scores to weights\n",
    "\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1) # weighted sum to get context vector\n",
    "\n",
    "        out = self.fc(context)\n",
    "        return out.squeeze()\n",
    "\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMSentiment(len(vocab), EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617dd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 391/391 [01:29<00:00,  4.36it/s, loss=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 391/391 [01:19<00:00,  4.94it/s, loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 391/391 [01:29<00:00,  4.39it/s, loss=0.0369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 391/391 [01:28<00:00,  4.44it/s, loss=0.00774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 391/391 [01:27<00:00,  4.45it/s, loss=0.00148] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    for texts, labels in loop:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=total_loss / (loop.n + 1))\n",
    "    \n",
    "    # Step the scheduler once per epoch\n",
    "    scheduler.step(total_loss / len(train_loader))  # at end of each epoch\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e934a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8615\n",
      "Precision: 0.8565\n",
      "Recall:    0.8693\n",
      "F1 Score:  0.8629\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_loader:\n",
    "        outputs = model(texts)\n",
    "        predicted = (torch.sigmoid(outputs) >= 0.50).float()  # only apply sigmoid here\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Now compute metrics on all collected predictions\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a1fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predictions: (tensor([0., 1.]), tensor([1965, 2035]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique predictions:\", torch.unique(torch.tensor(y_pred), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2005, 0: 1995})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Counter([sample[\"label\"] for sample in test_data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
