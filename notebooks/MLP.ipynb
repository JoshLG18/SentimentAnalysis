{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ddc4ef5",
   "metadata": {},
   "source": [
    "## MLP - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867026ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "import math\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "\n",
    "# set device\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# set seed\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)                           # Python random\n",
    "    np.random.seed(seed)                        # NumPy\n",
    "    torch.manual_seed(seed)                     # PyTorch CPU\n",
    "    torch.cuda.manual_seed_all(seed)            # PyTorch GPU (if using)\n",
    "    torch.backends.cudnn.deterministic = True   # For reproducibility\n",
    "    torch.backends.cudnn.benchmark = False      # Disable auto-tuning (slower but stable)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ========== Hyperparameters ==========\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 64\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "MAX_LEN = 300\n",
    "LEARNING_RATE = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17caf03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Find some twitter data ============\n",
    "\n",
    "# train_data = dataset[\"train\"]\n",
    "# test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Tokenizer and GloVe ==========\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "glove = GloVe(name=\"6B\", dim=EMBEDDING_DIM)\n",
    "\n",
    "def yield_glove_tokens(data_iter):\n",
    "    for example in data_iter:\n",
    "        tokens = tokenizer(example[\"text\"])\n",
    "        yield [token for token in tokens if token in glove.stoi]\n",
    "\n",
    "# ========== Build Vocab (only GloVe tokens) ==========\n",
    "vocab = build_vocab_from_iterator(yield_glove_tokens(train_data), specials=[\"<pad>\", \"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# ========== GloVe Coverage Check ==========\n",
    "known = sum(1 for token in vocab.get_itos() if token in glove.stoi)\n",
    "print(f\"GloVe coverage: {known / len(vocab):.2%}\")\n",
    "\n",
    "# ========== Preprocessing ==========\n",
    "def preprocess(example):\n",
    "    tokens = tokenizer(example[\"text\"])\n",
    "    input_ids = vocab(tokens)[:MAX_LEN]\n",
    "    label = int(example[\"label\"])\n",
    "    return {\"input_ids\": input_ids, \"label\": label}\n",
    "\n",
    "train_data = train_data.map(preprocess)\n",
    "test_data = test_data.map(preprocess)\n",
    "train_data.set_format(type=\"python\", columns=[\"input_ids\", \"label\"])\n",
    "test_data.set_format(type=\"python\", columns=[\"input_ids\", \"label\"])\n",
    "\n",
    "# ========== Collate Function ==========\n",
    "def collate_batch(batch):\n",
    "    texts = [torch.tensor(sample[\"input_ids\"], dtype=torch.int64) for sample in batch]\n",
    "    labels = [torch.tensor(sample[\"label\"], dtype=torch.float32) for sample in batch]\n",
    "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "    return texts_padded.to(device), torch.stack(labels).to(device)\n",
    "\n",
    "# ========== DataLoaders ==========\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          collate_fn=collate_batch, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=collate_batch, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ========== Check Class Balance ==========\n",
    "print(\"Label distribution in training set:\")\n",
    "print(Counter([sample[\"label\"] for sample in train_data]))\n",
    "\n",
    "# ========== Build Embedding Matrix ==========\n",
    "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
    "\n",
    "for idx, token in enumerate(vocab.get_itos()):\n",
    "    if token in glove.stoi:\n",
    "        embedding_matrix[idx] = glove[token]\n",
    "    else:\n",
    "        embedding_matrix[idx] = torch.randn(EMBEDDING_DIM) * 0.6  # small random vector for unknowns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
